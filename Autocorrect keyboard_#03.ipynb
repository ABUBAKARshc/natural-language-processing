{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba03463d",
   "metadata": {},
   "source": [
    "## With the context of machine learning, autocorrect is based on natural language processing. As the name suggests it is programmed to correct spellings and errors while typing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43e4610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing some necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textdistance\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b246830f",
   "metadata": {},
   "source": [
    "#### Like our smartphone uses history to match the type words whether it’s correct or not. So here we also need to use some words to put the functionality in our autocorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cc854db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first ten words in the text are: \n",
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'moby', 'dick', 'or', 'the', 'whale']\n",
      "There are 17354 unique words in the vocabulary\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "\n",
    "with open(\"moby.txt\",encoding=\"utf8\") as f:\n",
    "    file_name_data = f.read()\n",
    "    file_name_data = file_name_data.lower()\n",
    "    words = re.findall(\"\\w+\", file_name_data)\n",
    "    \n",
    "# This is our vocabulary\n",
    "V = set(words)\n",
    "print(f\"The first ten words in the text are: \\n{words[0:10]}\")\n",
    "print(f\"There are {len(V)} unique words in the vocabulary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8a6483",
   "metadata": {},
   "source": [
    "#### In the above code, we made a list of words, and now we need to build the frequency of those words, which can be easily done by using the counter function in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b0d055b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 14718), ('of', 6743), ('and', 6518), ('a', 4807), ('to', 4707), ('in', 4242), ('that', 3100), ('it', 2536), ('his', 2532), ('i', 2127)]\n"
     ]
    }
   ],
   "source": [
    "word_freq_dict = {}\n",
    "word_freq_dict = Counter(words)\n",
    "print(word_freq_dict.most_common()[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714a49ec",
   "metadata": {},
   "source": [
    "## Relative Frequency of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9394c6",
   "metadata": {},
   "source": [
    "#### Now we want to get the probability of occurence of each word, this equals the relative frequencies of the worlds:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d9f3ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = {}\n",
    "Total = sum(word_freq_dict.values())\n",
    "for k in word_freq_dict.keys():\n",
    "    probs[k] = word_freq_dict[k]/Total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfda7e9a",
   "metadata": {},
   "source": [
    "## Finding Similar Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae394f",
   "metadata": {},
   "source": [
    "#### We will sort similar words according to the jaccard distance by calculating the 2 grams Q of the words. Next we will return the 5 most similar words order by similarity and probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fdf3d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_autocorrect(input_word):\n",
    "    input_word = input_word.lower()\n",
    "    if input_word in V:\n",
    "        return 'Your word seems to be correct'\n",
    "    else:\n",
    "        similarities = [1 - (textdistance.Jaccard(qval=2).distance(v, input_word)) for v in word_freq_dict.keys()]\n",
    "        df = pd.DataFrame.from_dict(probs, orient='index').reset_index()\n",
    "        df = df.rename(columns={'index': 'Word', 0: 'Prob'})\n",
    "        df['Similarity'] = similarities\n",
    "        output = df.sort_values(['Similarity', 'Prob'], ascending=False).head()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fba8be",
   "metadata": {},
   "source": [
    "# Now, let’s find the similar words by using our autocorrect function:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dbacad9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>learn</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301</th>\n",
       "      <td>learning</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5831</th>\n",
       "      <td>learnt</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>learned</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>clear</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word      Prob  Similarity\n",
       "4842     learn  0.000040    0.666667\n",
       "2301  learning  0.000027    0.625000\n",
       "5831    learnt  0.000004    0.571429\n",
       "921    learned  0.000112    0.500000\n",
       "676      clear  0.000184    0.428571"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_autocorrect(\"learnig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff1aeea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
